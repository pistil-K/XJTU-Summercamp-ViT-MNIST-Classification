import pylayer as L

'''
    utility: pointwise two "2-d" lists with weight
    using operator op
    a = a * wa op b * wb
'''
def list2d_add(a, wa, b, wb):
    for x, y in zip(a, b):
        # print(len(x), len(y))
        for u, v in zip(x, y):
            # print('\t', u.shape, v.shape)
            u *= wa
            u += v * wb
def list2d_sub(a, wa, b, wb):
    for x, y in zip(a, b):
        # print(len(x), len(y))
        for u, v in zip(x, y):
            # print('\t', u.shape, v.shape)
            u *= wa
            u -= v * wb

class SGD(object):
    '''
        Implements stochastic gradient descent, with momentum features.

        The model could be sequential, must have forward(), backward();
        model.param_grads is generated by model.backward().
    '''
    def __init__(self, model, lr=1e-3, momentum=0.):
        self.lr = lr
        self.momentum = momentum
        self.last_step_grads = None
        self.model = model
        # maintains a reference of all trainable params of all layers
        self.params_ref = []
        for l in self.model.layers:
            # crappy implementation, not my bad
            if (isinstance(l, L.Linear)):
                self.params_ref.append((l.weight, l.bias))
            elif (isinstance(l, L.BatchNorm1d)):
                self.params_ref.append((l.gamma, l.beta))
            elif (isinstance(l, L.BatchNorm2d)):
                self.params_ref.append((l.gamma, l.beta))
            elif (isinstance(l, L.ReLU)):
                self.params_ref.append(())
            elif (isinstance(l, L.CrossEntropyLossWithSoftmax)):
                self.params_ref.append(())
            elif (isinstance(l, L.Conv2d)):
                self.params_ref.append((l.weight, l.bias))
            elif (isinstance(l, L.MaxPool2d)):
                self.params_ref.append(())
            elif (isinstance(l, L.Flatten)):
                self.params_ref.append(())
            elif (isinstance(l, L.BasicBlock)):
                self.params_ref.append(tuple(l.params_ref))
            elif (isinstance(l, L.BottleNeck)):
                self.params_ref.append(tuple(l.params_ref))

    def step(self):
        if (self.momentum > 0. and self.last_step_grads != None):
            list2d_add(self.model.param_grads, 1. - self.momentum,
                        self.last_step_grads, self.momentum)
        list2d_sub(self.params_ref, 1., self.model.param_grads, self.lr)
        self.last_step_grads = self.model.param_grads.copy()
